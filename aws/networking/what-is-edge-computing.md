# Edge Computing

## What is edge computing?
Edge computing is a networking philosophy focused on bringing computing as close to the source of data as possible in order to reduce latency and bandwidth use. In simpler terms, edge computing means running fewer processes in the cloud and moving those processes to local places, such as on a user’s computer, an IoT device, or an edge server. Bringing computation to the network’s edge minimizes the amount of long-distance communication that has to happen between a client and server.

## What is the network edge?
For Internet devices, the network edge is where the device, or the local network containing the device, communicates with the Internet. The edge is a bit of a fuzzy term; for example a user’s computer or the processor inside of an IoT camera can be considered the network edge, but the user’s router, ISP, or local edge server are also considered the edge. The important takeaway is that the edge of the network is geographically close to the device, unlike origin servers and cloud servers, which can be very far from the devices they communicate with.

## What differentiates edge computing from other computing models?

Edge computing is a distributed computing paradigm that brings computation and data storage closer to the location where it is needed, rather than relying solely on a centralized cloud-based data center. This approach has several key differentiators from other computing models, such as cloud computing and traditional on-premises computing:

### Proximity to Data Source:
- **Edge Computing:** Data processing occurs close to the data source, reducing latency and improving response times.
- **Cloud Computing:** Centralized data processing in remote data centers may introduce latency.
- **On-Premises Computing:** Data processing within an organization's own data center, potentially with lower latency than cloud computing.

### Bandwidth Usage:
- **Edge Computing:** Reduces the need for large data transfers by processing data locally.
- **Cloud Computing:** Relies on data transfer to and from the cloud, potentially straining network bandwidth.
- **On-Premises Computing:** Involves local data processing but lacks the geographical distribution advantages of edge computing.

### Real-Time Processing:
- **Edge Computing:** Well-suited for real-time or low-latency processing in applications like industrial automation and autonomous vehicles.
- **Cloud Computing:** May introduce latency due to data transfer and processing in remote data centers.
- **On-Premises Computing:** Local processing but lacks the distributed nature of edge computing.

### Scalability:
- **Edge Computing:** Highly scalable, leveraging distributed devices and resources across the network.
- **Cloud Computing:** Offers elastic scalability for applications with fluctuating workloads.
- **On-Premises Computing:** Scalability may be limited by available hardware resources.

### Use Cases:
- **Edge Computing:** Common in IoT applications, real-time analytics, video processing, and low-latency response scenarios.
- **Cloud Computing:** Suited for a wide range of applications, including web hosting, big data analytics, machine learning, and enterprise applications.
- **On-Premises Computing:** Often used for running legacy applications, databases, and critical systems.

In summary, edge computing differentiates itself by processing data close to the source, reducing latency, and providing real-time capabilities, making it suitable for specific use cases.


